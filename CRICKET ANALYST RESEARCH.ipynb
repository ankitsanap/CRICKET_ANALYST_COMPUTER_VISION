{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket analytics using computer vision for live field tracking of players involves various parameters that are essential to ensure accurate tracking and analysis. Here are some of the important parameters required:\n",
    "\n",
    "Camera positioning: The positioning of cameras is crucial for accurate tracking of players. The cameras need to be placed in such a way that they capture the entire field of play and provide a clear view of each player.\n",
    "\n",
    "Frame rate: The frame rate of the cameras should be high enough to capture fast-moving players and the ball accurately. A higher frame rate ensures that more information is captured, which helps in accurate tracking.\n",
    "\n",
    "Resolution: The resolution of the cameras should be high enough to capture clear images of the players and the ball. Higher resolution ensures that even small details are captured, which can be helpful in analyzing player movements.\n",
    "\n",
    "Image processing algorithms: Image processing algorithms are essential for analyzing the images captured by the cameras. These algorithms are used to detect and track players, the ball, and other objects on the field.\n",
    "\n",
    "Machine learning models: Machine learning models are used to analyze the data captured by the cameras and provide insights into player performance. These models are trained on large datasets of cricket matches and are used to identify patterns in player movements, ball trajectory, and other aspects of the game.\n",
    "\n",
    "Calibration: The cameras and the tracking system need to be calibrated before each match to ensure accuracy. This involves adjusting the camera angles, lens distortion, and other factors to ensure that the tracking system is accurate.\n",
    "\n",
    "Data storage: The data captured by the cameras needs to be stored in a secure and reliable manner. This requires a robust data storage system that can handle large volumes of data and provide fast access to the data when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML ALGO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs): CNNs are widely used for object detection, which is an important component of cricket analytics. CNNs can be trained to detect and track players and the ball accurately.\n",
    "\n",
    "Support Vector Machines (SVMs): SVMs are commonly used for classification tasks, such as classifying the type of shot played by a batsman or the type of ball bowled by a bowler.\n",
    "\n",
    "Random Forest: Random Forest is an ensemble learning method that is widely used for classification tasks in cricket analytics. It can be used to predict the outcome of a match or the performance of a player.\n",
    "\n",
    "Recurrent Neural Networks (RNNs): RNNs are used for sequence modeling, such as predicting the trajectory of the ball or the movements of a player over time.\n",
    "\n",
    "Decision Trees: Decision trees are used for classification tasks in cricket analytics, such as predicting the outcome of a match or the performance of a player.\n",
    "\n",
    "Naive Bayes: Naive Bayes is a probabilistic algorithm that can be used for classification tasks in cricket analytics, such as predicting the type of shot played by a batsman or the type of ball bowled by a bowler.\n",
    "\n",
    "K-Nearest Neighbors (KNN): KNN is a simple algorithm that can be used for classification tasks in cricket analytics. It can be used to predict the outcome of a match or the performance of a player based on the performance of similar players in the past.\n",
    "\n",
    "# By using a combination of these machine learning algorithms, cricket analytics using computer vision for live field tracking of players can provide valuable insights into player performance and improve the overall quality of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Collection\n",
    "The first step is to collect data from cricket matches. This includes live video feeds from the matches, as well as data on player and team statistics. The data needs to be preprocessed and labeled to be useful for machine learning algorithms.\n",
    "\n",
    "Step 2: Object Detection\n",
    "The next step is to use computer vision algorithms, such as Object Detection, to identify different objects in the video frames, such as players and the ball. This can be done using pre-trained models or custom models trained on the collected data.\n",
    "\n",
    "Step 3: Object Tracking\n",
    "Once the objects are detected, Object Tracking algorithms can be used to track the movement of players and the ball across the video frames. This helps in analyzing player movements and ball trajectory.\n",
    "\n",
    "Step 4: Pose Estimation\n",
    "Pose Estimation algorithms can be used to detect the posture of players, such as whether they are standing, running, or in a particular position like a bowler or a fielder. This helps in identifying the actions performed by players.\n",
    "\n",
    "Step 5: Action Recognition\n",
    "Action Recognition algorithms can be used to recognize different actions performed by players, such as hitting the ball, catching it, or running. This helps in analyzing player performance and identifying areas for improvement.\n",
    "\n",
    "Step 6: Data Analysis\n",
    "The data collected from the above steps can be analyzed using machine learning models to identify patterns in player movements, ball trajectory, and other aspects of the game. This helps in providing insights into player performance and optimizing team strategies.\n",
    "\n",
    "Step 7: Visualization\n",
    "The results of the data analysis can be visualized using charts, graphs, and other visualizations. This helps in presenting the insights in an understandable and actionable way for coaches, players, and teams."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Collection\n",
    "The first step is to collect data from cricket matches. This includes live video feeds from the matches, as well as data on player and team statistics. The data needs to be preprocessed and labeled to be useful for machine learning algorithms.\n",
    "\n",
    "CricSheet: CricSheet is an open-source project that provides ball-by-ball data for cricket matches. The data includes information on the scorecard, player performances, and ball-by-ball commentary. You can download the data from their website.\n",
    "\n",
    "ESPNcricinfo: ESPNcricinfo is a popular cricket website that provides live scores, news, and analysis. They also provide data on past matches, including scorecards, player statistics, and ball-by-ball commentary. You can access the data on their website.\n",
    "\n",
    "CricketArchive: CricketArchive is another website that provides historical data on cricket matches, including scorecards and player statistics. You can search for specific matches or players to find relevant data.\n",
    "\n",
    "T20Stats: T20Stats is a website that provides data on T20 cricket matches. The data includes information on scorecards, player performances, and match statistics. You can access the data on their website.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Object Detection\n",
    "The next step is to use computer vision algorithms, such as Object Detection, to identify different objects in the video frames, such as players and the ball. This can be done using pre-trained models or custom models trained on the collected data.\n",
    "\n",
    "\n",
    "\n",
    "Object detection is a crucial step in cricket analytics using computer vision. It helps in detecting different objects in the video frames, such as players, the ball, and other objects on the field.\n",
    "\n",
    "There are various pre-trained models available for object detection, such as YOLO, SSD, Faster R-CNN, and Mask R-CNN, that can be used to identify objects in the video frames. These models can be fine-tuned on the collected data to improve their accuracy in detecting cricket-specific objects.\n",
    "\n",
    "Alternatively, custom models can also be trained on the collected data using deep learning frameworks such as TensorFlow, PyTorch, or Keras. This involves creating a training dataset with labeled images and training a neural network to detect objects in the images.\n",
    "\n",
    "Once the object detection model is trained, it can be used to detect players and the ball in real-time during a cricket match. The detected objects can then be tracked over time to extract various features such as the position, speed, and trajectory of the players and the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 8\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X30sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X30sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load YOLOv3 weights and configuration\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X30sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m net \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mdnn\u001b[39m.\u001b[39;49mreadNet(\u001b[39m\"\u001b[39;49m\u001b[39myolov3.weights\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myolov3.cfg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X30sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m \u001b[39m# Define classes to detect (in this case, just the ball)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X30sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m classes \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mball\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLOv3 weights and configuration\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Define classes to detect (in this case, just the ball)\n",
    "classes = [\"ball\"]\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(\"match.mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read video frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Perform object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"ball\":\n",
    "                box = detection[:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Perform non-maximum suppression to remove overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes around detected objects\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show video frame with bounding boxes\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    # Exit on key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Object Tracking\n",
    "Once the objects are detected, Object Tracking algorithms can be used to track the movement of players and the ball across the video frames. This helps in analyzing player movements and ball trajectory.\n",
    "\n",
    "\n",
    " Object tracking is an essential step in cricket analytics using computer vision, as it helps to track the movement of players and the ball across the video frames. This information can be used to analyze player movements, ball trajectory, and other key features of the game.\n",
    "\n",
    "There are various object tracking algorithms available, such as Kalman filters, Particle filters, and Mean-Shift, that can be used to track objects across frames. These algorithms use the object detection results from the previous step to estimate the position of the objects in the current frame.\n",
    "\n",
    "Once the objects are tracked across multiple frames, various features such as the position, speed, and trajectory of the players and the ball can be extracted. This information can be used to analyze player performance, team strategy, and other aspects of the game. For example, it can be used to identify the best fielding positions for a particular player, analyze the effectiveness of a bowler's delivery, or track the movement of a particular player during the course of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "# Load the custom object detection model\n",
    "detection_model = tf.saved_model.load('/path/to/custom/detection/model')\n",
    "\n",
    "# Load the custom object tracking model\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "# Initialize variables for tracking\n",
    "bbox = None\n",
    "frame_count = 0\n",
    "\n",
    "# Open the video stream\n",
    "cap = cv2.VideoCapture('/path/to/video/file')\n",
    "\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # Increment the frame count\n",
    "        frame_count += 1\n",
    "\n",
    "        # Run the object detection model on the frame\n",
    "        detections = detection_model(frame)\n",
    "\n",
    "        # Loop through the detected objects\n",
    "        for detection in detections:\n",
    "            # Check if the object is a player or the ball\n",
    "            if detection.class == 'player' or detection.class == 'ball':\n",
    "                # Get the bounding box coordinates\n",
    "                bbox = detection.bbox\n",
    "\n",
    "        if bbox is not None:\n",
    "            # Initialize the tracker with the bounding box\n",
    "            tracker.init(frame, bbox)\n",
    "\n",
    "            # Update the tracker on subsequent frames\n",
    "            ok, bbox = tracker.update(frame)\n",
    "\n",
    "            # Draw the bounding box on the frame\n",
    "            if ok:\n",
    "                cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), \n",
    "                              (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3])),\n",
    "                              (0, 255, 0), 2)\n",
    "            else:\n",
    "                bbox = None\n",
    "\n",
    "        # Display the current frame\n",
    "        cv2.imshow('Cricket Analytics', frame)\n",
    "\n",
    "        # Exit if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Pose Estimation\n",
    "Pose Estimation algorithms can be used to detect the posture of players, such as whether they are standing, running, or in a particular position like a bowler or a fielder. This helps in identifying the actions performed by players.\n",
    "\n",
    "\n",
    "Pose estimation is another important step in cricket analytics using computer vision, as it helps to detect the posture of players and identify their actions during the game.\n",
    "\n",
    "There are various pose estimation algorithms available, such as OpenPose, that can be used to detect the position of key body joints, such as the head, shoulders, elbows, hips, knees, and ankles. These algorithms can be used to track the movement of players and identify their actions during the game, such as running, jumping, or throwing.\n",
    "\n",
    "Once the posture of the players is detected, various features such as the position, speed, and direction of the players can be extracted. This information can be used to analyze player performance, team strategy, and other aspects of the game. For example, it can be used to identify the running speed of a particular player, analyze the throwing technique of a fielder, or track the movement of a particular player during the course of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import openpose as op\n",
    "\n",
    "# Load OpenPose model\n",
    "params = {\"model_folder\": \"models/\"}\n",
    "openpose = op.OpenPose(params)\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('cricket_video.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Perform pose estimation\n",
    "    keypoints, output_image = openpose.forward(frame, True)\n",
    "\n",
    "    # Draw the keypoints on the output image\n",
    "    cv2.imshow(\"Output\", output_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we first load the OpenPose model by specifying the model folder where the model files are stored. We then load a video file using the cv2.VideoCapture() function. Inside the while loop, we read a frame from the video and pass it to the openpose.forward() function to perform pose estimation. This function returns the detected keypoints and an output image with the keypoints drawn on it. Finally, we display the output image using cv2.imshow() and wait for the user to press the 'q' key to exit the loop.\n",
    "\n",
    "Note that this code only performs pose estimation and does not track the players or the ball. To perform tracking, we need to use object detection and tracking algorithms as described in the previous steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Action Recognition\n",
    "Action Recognition algorithms can be used to recognize different actions performed by players, such as hitting the ball, catching it, or running. This helps in analyzing player performance and identifying areas for improvement.\n",
    "\n",
    "\n",
    " Action recognition is an important step in cricket analytics using computer vision, as it helps to recognize different actions performed by players during the game.\n",
    "\n",
    "There are various action recognition algorithms available, such as 3D CNNs (Convolutional Neural Networks), that can be used to classify actions performed by players based on their posture and movement. These algorithms can be trained on a large dataset of cricket match videos to recognize different actions, such as hitting the ball, catching it, or running.\n",
    "\n",
    "Once the actions are recognized, various features such as the frequency, accuracy, and success rate of the actions can be extracted. This information can be used to analyze player performance, team strategy, and other aspects of the game. For example, it can be used to identify the batting performance of a particular player, analyze the fielding skills of a team, or track the success rate of a particular action during the course of the game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames, img_height, img_width, num_channels)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Data Analysis\n",
    "The data collected from the above steps can be analyzed using machine learning models to identify patterns in player movements, ball trajectory, and other aspects of the game. This helps in providing insights into player performance and optimizing team strategies.\n",
    "\n",
    "\n",
    " Data analysis is a crucial step in cricket analytics using computer vision, as it helps to extract insights and patterns from the data collected in the previous steps.\n",
    "\n",
    "There are various machine learning models that can be used for data analysis, such as clustering algorithms, classification algorithms, and regression algorithms. These models can be used to identify patterns in player movements, ball trajectory, and other aspects of the game, which can be used to provide insights into player performance and optimize team strategies.\n",
    "\n",
    "For example, data analysis can be used to identify the best fielding positions for a particular player, analyze the effectiveness of a bowler's delivery, or track the movement of a particular player during the course of the game. It can also be used to identify patterns in the data, such as common player movements or successful team strategies, which can be used to optimize team performance and improve overall results.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load data and split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "# Train a decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the decision tree classifier on the testing set\n",
    "tree_acc = tree_clf.score(X_test, y_test)\n",
    "print(\"Decision Tree Accuracy:\", tree_acc)\n",
    "\n",
    "# Train a random forest classifier with 100 trees\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the random forest classifier on the testing set\n",
    "rf_acc = rf_clf.score(X_test, y_test)\n",
    "print(\"Random Forest Accuracy:\", rf_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're using decision trees and random forests to classify cricket actions based on the data collected from the previous steps. We're using the load_data() function to load the data and split it into training and testing sets. Then we're training a decision tree classifier and a random forest classifier on the training set, and evaluating their accuracy on the testing set. Finally, we're printing the accuracy scores of both classifiers.\n",
    "\n",
    "Of course, this is just an example implementation and there are many other machine learning algorithms that could be used for cricket analytics, depending on the specific problem and the data available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Visualization\n",
    "The results of the data analysis can be visualized using charts, graphs, and other visualizations. This helps in presenting the insights in an understandable and actionable way for coaches, players, and teams.\n",
    "\n",
    "\n",
    " Visualization is a crucial step in cricket analytics using computer vision, as it helps to present the insights and patterns identified in the data analysis in an understandable and actionable way for coaches, players, and teams.\n",
    "\n",
    "There are various visualization techniques that can be used, such as scatter plots, line graphs, heatmaps, and other types of charts and graphs. These visualizations can be used to present different types of data, such as player performance, team strategies, and game statistics.\n",
    "\n",
    "For example, a scatter plot can be used to visualize the relationship between the batting average and strike rate of a particular player, a line graph can be used to visualize the changes in a team's performance over the course of a season, and a heatmap can be used to visualize the distribution of successful deliveries by a particular bowler.\n",
    "\n",
    "Visualization can also be used to communicate the insights and patterns identified in the data analysis to coaches, players, and teams, helping them to make data-driven decisions and improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with player stats\n",
    "data = {'Player': ['A', 'B', 'C', 'D', 'E'],\n",
    "        'Batting Average': [32.5, 27.8, 42.3, 38.9, 45.2],\n",
    "        'Strike Rate': [128.5, 139.2, 123.7, 136.4, 150.6]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(df['Batting Average'], df['Strike Rate'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Player Performance')\n",
    "plt.xlabel('Batting Average')\n",
    "plt.ylabel('Strike Rate')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line Graph Example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 8, 6, 4, 2]\n",
    "\n",
    "# Create the line graph\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Set the labels\n",
    "plt.xlabel('Matches')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap Example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = np.array([[10, 20, 30, 40], [50, 60, 70, 80], [90, 100, 110, 120]])\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = plt.pcolor(data, cmap=plt.cm.Blues)\n",
    "\n",
    "# Set the tick marks\n",
    "plt.xticks(np.arange(0.5, len(data[0]), 1), range(len(data[0])))\n",
    "plt.yticks(np.arange(0.5, len(data), 1), range(len(data)))\n",
    "\n",
    "# Show the colorbar\n",
    "plt.colorbar(heatmap)\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
